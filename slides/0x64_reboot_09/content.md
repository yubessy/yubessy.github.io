class: center, middle

# 良い木とは何か

#### @yubessy

#### 0x64物語 Reboot #09 "木"

---

class: center, middle

# 木

---

class: center, middle

#### このLTでは

# 決定木

---

## 決定木

TODO: 図

---

## 決定木

* 決定をするための木
* 独立変数(説明変数)の値から従属変数(目的変数)の値を求める

#### 決定ステップ

1. １つの独立変数を選択する
2. その値に基づいて分岐する
3. 1,2を繰り返し、末端にたどり着くと従属変数の値が求まる

---

## 決定木学習

TODO: 図

---

## 決定木学習

* 機械学習の１手法
* データに対して正しい出力が得られるモデルを生成

#### データ

* 組 (独立変数群, 従属変数) の集合

#### モデル

* 入力: 各組の独立変数群の値
* 出力: 各組の従属変数の値

---

## 良い決定木とは？

TODO: 図

---

## 良い決定木とは？

* ノードや枝の数に上限がなければ <br>
  データに対して正しい決定を与える木は複数存在する
* そのなかでどれが **最も良い決定木** なのか？
    * 枝が少ない？
    * 深さが少ない？
* → 一概には決められない

---

## 決定木学習アルゴリズム

* ある規準に従い、その規準において良い木を生成する
* 代表的なアルゴリズム
    * ID3: 最も基本的なアルゴリズム
    * C4.5: ID3の改良版

#### （ちなみに）

* Random Forest, Gradient Boosted Tree は <br>
  単一の決定木を生成するアルゴリズムではない
* これらは複数の決定木を組合せて良いモデルを生成する手法

---

## ID3 (Iterative Dichotomiser 3)

* 各時点で最大の **情報利得** が得られる独立変数を選択
* 選択した独立変数の値による分岐を生成
* 貪欲法(greedy method)の一種

#### 情報利得

* 不確かな事象Xについて、情報Iを知ることでどれくらい不確かさが減るか
  * X: 花火大会が開催されるか
  * I: 天気, 風速, 湿度, ...
* 不確かさ・情報利得は **計算できる**

---

## エントロピー

* 事象Xの不確かさ = Xのエントロピー

TODO: 数式

---

## エントロピー

* 例: 花火大会が開催されるか

TODO: 数式

---

## 情報利得

* データIによる場合分け後の事象Xのエントロピーの減少量

---

## 情報利得

* 例: 天気がわかっているとき、花火大会が開催されるか

TODO: 数式

---

## ID3情報利得

* 情報利得が最も大きい独立変数による分岐を繰り返す

TODO: 図

---

## ID3 pros/cons

#### pros

* 安定（多少データが入れ替わっても木が変わりにくい）
* 高速（`O(n log(n))` ）

#### cons

* 得られる木が最良であるとは限らない
* 連続値変数にはそのまま適用できない

---

## 参考

http://www.sist.ac.jp/~kanakubo/research/reasoning_kr/decision_tree.html
